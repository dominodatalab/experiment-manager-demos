{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/mnt/code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'integration-test'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['DOMINO_STARTING_USERNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Just some imports you will need\n",
    "import mlflow\n",
    "import jwt\n",
    "import json\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does MLFlow know the URI of Tracking Server and the Authentication Token?\n",
    "MLFlow relies on two environment variables\n",
    "- `MLFLOW_TRACKING_URI` - Which is used to find the location of the tracking uri\n",
    "- `MLFLOW_TRACKING_TOKEN` - The value of which is passed as an Authentication Bearer token to every Rest call from the invoking Python/Java/R API. With the Domino Experiment Manager, this token is generated on your behalf by the underlying Domino Infrastructure when a call is made from the workspace. Note how the `MLFLOW_TRACKING_URI` is a `localhost` call and is running as side-car in your workload pod. It is responsible for invoking the MLflow proxy with this token. You will not have access to this token from inside the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_TRACKING_URI: http://127.0.0.1:8765\n"
     ]
    }
   ],
   "source": [
    "print('MLFLOW_TRACKING_URI: ' + os.environ['MLFLOW_TRACKING_URI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MLFlow Client\n",
    "We are ready to start using MLFLOW. Let us create an MLFlow Client. Note that we do not provide any parameters. It knows the Tracking URI and our Authentication Token from the environment variables created by the workspace environment.\n",
    "\n",
    "> Your credentials are passed transparently. No configuration is needed from the user end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new experiment or use an existing one\n",
    "\n",
    "Provide a value for `myprefix` variable below which is unused to create a brand new \n",
    "experiment. Or simply leave it as it is. The experiment name will be the combination of \n",
    "- myprefix\n",
    "- today's date\n",
    "- user-name\n",
    "- project-name\n",
    "\n",
    "If the experiment with that name exists, you will be using it to create runs or a new experiment will be created and you will create runs into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-SCIKIT-LEARN-EXPERIMENT-66b3618bffe62d0ab852cd05\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time_str = now.strftime(\"%m-%d-%Y\")\n",
    "prefix = 'DEMO-SCIKIT-LEARN-EXPERIMENT'\n",
    "starting_user_name = os.environ['DOMINO_STARTING_USERNAME']\n",
    "project_id = os.environ['DOMINO_PROJECT_ID']\n",
    "\n",
    "experiment_name = f'{prefix}-{project_id}'\n",
    "model_name = f'model-{prefix}'\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MLFLOW Specific\n",
    "experiment = client.get_experiment_by_name(name=experiment_name)\n",
    "if(experiment is None):\n",
    "    print('Creating experiment ')\n",
    "    client.create_experiment(name=experiment_name)\n",
    "    experiment = client.get_experiment_by_name(name=experiment_name)\n",
    "print(experiment_name)\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MLFLOW Specific\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now multiple runs in that experiment for various values of alpha and l1_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Run\n",
      "Alpha : 0.7\n",
      "L1_Ratio : 0.6\n",
      "Elasticnet model (alpha=0.700000, l1_ratio=0.600000):\n",
      "  RMSE: 0.7627246800819057\n",
      "  MAE: 0.6287888854224957\n",
      "  R2: 0.03747693976498101\n",
      "Start Run\n",
      "Alpha : 0.7999999999999999\n",
      "L1_Ratio : 0.65\n",
      "Elasticnet model (alpha=0.800000, l1_ratio=0.650000):\n",
      "  RMSE: 0.7638598543917334\n",
      "  MAE: 0.6312333902950296\n",
      "  R2: 0.03460973336968853\n",
      "Start Run\n",
      "Alpha : 0.8999999999999999\n",
      "L1_Ratio : 0.7000000000000001\n",
      "Elasticnet model (alpha=0.900000, l1_ratio=0.700000):\n",
      "  RMSE: 0.7641712496114665\n",
      "  MAE: 0.6322852069908985\n",
      "  R2: 0.03382247066057176\n",
      "Start Run\n",
      "Alpha : 0.9999999999999999\n",
      "L1_Ratio : 0.7500000000000001\n",
      "Elasticnet model (alpha=1.000000, l1_ratio=0.750000):\n",
      "  RMSE: 0.7642701552596672\n",
      "  MAE: 0.6330621329833208\n",
      "  R2: 0.033572352381476045\n"
     ]
    }
   ],
   "source": [
    "# Read the wine-quality csv file from the URL\n",
    "csv_url = (\n",
    "     \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    ")\n",
    "try:\n",
    "     data = pd.read_csv(csv_url, sep=\";\")\n",
    "except Exception as e:\n",
    "     logger.exception(\n",
    "          \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "      )\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"quality\"], axis=1)\n",
    "test_x = test.drop([\"quality\"], axis=1)\n",
    "train_y = train[[\"quality\"]]\n",
    "test_y = test[[\"quality\"]]\n",
    "\n",
    "\n",
    "my_log = \"This is a test log\"\n",
    "with open(\"/tmp/test.txt\", 'w') as f:\n",
    "    f.write(my_log)\n",
    "with open(\"/tmp/test.log\", 'w') as f:\n",
    "    f.write(my_log)\n",
    "\n",
    "    \n",
    "    \n",
    "#run_tags={'mlflow.user':os.environ['DOMINO_STARTING_USERNAME']}\n",
    "#Change user name\n",
    "alpha = 0.7\n",
    "l1_ratio = 0.6\n",
    "while(alpha<1):\n",
    "    #Start a run in the experiment\n",
    "    with mlflow.start_run():        \n",
    "        print('Start Run')\n",
    "        print('Alpha : ' + str(alpha))\n",
    "        print('L1_Ratio : ' + str(l1_ratio))\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "        mlflow.log_metric('fake_metric',0.46)\n",
    "        mlflow.sklearn.log_model(lr,  model_name)\n",
    "        alpha=alpha+0.1\n",
    "        l1_ratio = l1_ratio + 0.05        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the MLFlow UI and view the following:\n",
    "- Experiment\n",
    "- Runs in the experiment\n",
    "- Compare runs for performance\n",
    "- View model and its versions (One per run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each run of this experiment let us review the list of artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " def print_artifact_info(artifact):\n",
    "    print(f\"   artifact path: {artifact.path}, is_dir: {artifact.is_dir}\")\n",
    "    #print(\"is_dir: {}\".format(artifact.is_dir))\n",
    "    #print(\"size: {}\".format(artifact.file_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "e = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(e.artifact_location)\n",
    "rl = mlflow.search_runs(e.experiment_id,output_format=\"list\")\n",
    "\n",
    "for r in rl:\n",
    "    run_id=r.info.run_id\n",
    "    print(f\"Artifacts for run id {run_id}\")\n",
    "    ls = client.list_artifacts(run_id)\n",
    "    for l in ls:\n",
    "        print_artifact_info(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the latest model version for each stage (None, Staging, Production, Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client =  mlflow.tracking.MlflowClient()\n",
    "registered_model = client.get_registered_model(model_name)\n",
    "\n",
    "versions = registered_model.latest_versions\n",
    "#print(registered_model)\n",
    "#print(f\"Number of Model Versions ={versions}\")\n",
    "model_version=None\n",
    "\n",
    "if(len(versions)>1):\n",
    "    #print(versions[1])\n",
    "    model_version = versions[1]\n",
    "else:\n",
    "    model_version = versions[0]\n",
    "    \n",
    "print(f\"Most Recent Model Name={model_version.name} and Most Recent Model Version={model_version.version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Downloading Artifacts Locally\n",
    "\n",
    "This is essential when you are deploying a specific model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(model_version)\n",
    "run_id=model_version.run_id\n",
    "artifact_path=model_version.source\n",
    "#print(artifact_path)\n",
    "home_dir = os.path.expanduser('~')\n",
    "download_path=f'{home_dir}/{run_id}'\n",
    "mlflow.artifacts.download_artifacts(run_id=run_id,dst_path=download_path)\n",
    "print(f\"The artifacts for {run_id} will be downloaded to the folder {download_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! ls /home/ubuntu/c139836db5c44588a2b022c75e7fa991/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fetch all model versions for a registered model (Not just the latest one as shown above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "filter_string=f\"name='{model_name}'\"\n",
    "results = mlflow.search_model_versions(filter_string=filter_string)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True --inplace *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
