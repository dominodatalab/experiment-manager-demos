{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8acb8-29f1-4bc4-b5a4-89da5b9445ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo /opt/conda/bin/pip install numpy==1.20.0\n",
    "!sudo /opt/conda/bin/pip install tbparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e135d273-68a6-48ea-b67c-c31bf59ade68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/mnt/code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323a43dc-5f97-4118-af3d-201256af0488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following import and function call are the only additions to code required\n",
    "# to automatically log metrics and parameters to MLflow.\n",
    "import mlflow\n",
    "from domino_mlflow_utils.mlflow_utilities import *\n",
    "mlflow_utils = DominoMLflowUtilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89483ff9-2f7a-419d-8dcd-60a3cfff7616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSORBOARD-SELF-LOGGGING-integration-test-Experiment-Manager-Demos\n"
     ]
    }
   ],
   "source": [
    "prefix = 'TENSORBOARD-SELF-LOGGGING'\n",
    "starting_user_name = os.environ['DOMINO_STARTING_USERNAME']\n",
    "project_name = os.environ['DOMINO_PROJECT_NAME']\n",
    "experiment_name = f'{prefix}-{starting_user_name}-{project_name}'\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01dbf33b-0b7c-4b01-b668-3cefbb08ec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 13:24:23 INFO mlflow.tracking.fluent: Experiment with name 'Experiment-Manager-Demos-mlflow_tensorboard' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for active runs, Active Run= None\n",
      "Started new run with run_id: a41887b836b741cf9bae1bc1a1207a41\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "## Apply Autologging for Tensorflow\n",
    "mlflow.tensorflow.autolog()\n",
    "experiment_name= os.environ['DOMINO_PROJECT_NAME'] + \"-mlflow_tensorboard\"\n",
    "mlflow_utils.init(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402969e1-9f1a-4b7b-b8c5-c0e3dcc7c7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Don't use GPU\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\"\"\"Trains and evaluate a simple MLP\n",
    "on the Reuters newswire topic classification task.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "      return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "      ])\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d245e77-b00b-4b4c-9043-1190db4ac9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/logs-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 13:25:15.690098: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2024-08-07 13:25:15.690126: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2024-08-07 13:25:15.690359: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2024-08-07 13:25:16.735559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2024-08-07 13:25:16.752318: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2899930000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  20/1875 [..............................] - ETA: 13s - loss: 1.3660 - accuracy: 0.6203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 13:25:16.987437: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2024-08-07 13:25:16.987472: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2024-08-07 13:25:16.990889: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2024-08-07 13:25:16.991545: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2024-08-07 13:25:16.992471: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16\n",
      "2024-08-07 13:25:16.993088: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16/run-66b361a0ffe62d0ab852cd10-p46nm.trace.json.gz\n",
      "2024-08-07 13:25:16.994572: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16\n",
      "2024-08-07 13:25:16.994687: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16/run-66b361a0ffe62d0ab852cd10-p46nm.memory_profile.json.gz\n",
      "2024-08-07 13:25:16.994817: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16Dumped tool data for xplane.pb to /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16/run-66b361a0ffe62d0ab852cd10-p46nm.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16/run-66b361a0ffe62d0ab852cd10-p46nm.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16/run-66b361a0ffe62d0ab852cd10-p46nm.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16/run-66b361a0ffe62d0ab852cd10-p46nm.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /tmp/logs-4/train/plugins/profile/2024_08_07_13_25_16/run-66b361a0ffe62d0ab852cd10-p46nm.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2174 - accuracy: 0.9359 - val_loss: 0.1084 - val_accuracy: 0.9676\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0969 - accuracy: 0.9709 - val_loss: 0.0957 - val_accuracy: 0.9709\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0690 - accuracy: 0.9781 - val_loss: 0.0766 - val_accuracy: 0.9763\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 0.0679 - val_accuracy: 0.9792\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 13:26:06 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n",
      "2024/08/07 13:26:06 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2024-08-07 13:26:06.381977: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpueidj4es/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 13:26:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/opt/conda/envs/tensorboard/lib/python3.9/site-packages/_distutils_hack/__init__.py:32: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f349b726c40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff01d0-f50f-442a-81da-e4ee27509b68",
   "metadata": {},
   "source": [
    "## Download Tensorboard Logs\n",
    "\n",
    "The next cell demonstrates how to fetch the tensorboard logs for any run for which these logs have been registered.\n",
    "\n",
    "A local tensorboard instance can be used to render these logs. The benefit of this approach is that it can be used to register tensorboard logs for any experiment run and can be downloaded when needed for review. They do not have to be stored in your workspace or repo.\n",
    "\n",
    "You can go to the run artifacts UI to verify the detailed logs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f211ea7e-e8fd-4c20-a4b0-e51bf570e422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artifacts for a41887b836b741cf9bae1bc1a1207a41 will be downloaded to the folder /home/ubuntu/a41887b836b741cf9bae1bc1a1207a41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model', 'tensorboard_logs', 'model_summary.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = mlflow.active_run()\n",
    "run_id=r.info.run_id\n",
    "home_dir = os.path.expanduser('~')\n",
    "download_path=f'{home_dir}/{run_id}'\n",
    "mlflow.artifacts.download_artifacts(run_id=run_id,dst_path=download_path)\n",
    "print(f\"The artifacts for {run_id} will be downloaded to the folder {download_path}\")\n",
    "os.listdir(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a93150-0ed3-46a7-b625-809a7163c9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  model_summary.txt  tensorboard_logs\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ubuntu/a41887b836b741cf9bae1bc1a1207a41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092a2981-d12d-4eb6-89e6-205ab83389c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id: a41887b836b741cf9bae1bc1a1207a41; status: RUNNING\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mlflow_utils.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef417273-cc0f-48d2-916b-07a6ff0d5e61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/03_tensorboard_example.ipynb to notebook\n",
      "[NbConvertApp] Writing 10651 bytes to /mnt/code/notebooks/basic/03_tensorboard_example.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/mlflow-basic-autologging.ipynb to notebook\n",
      "[NbConvertApp] Writing 13626 bytes to /mnt/code/notebooks/basic/mlflow-basic-autologging.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/mlflow-basic.ipynb to notebook\n",
      "[NbConvertApp] Writing 12759 bytes to /mnt/code/notebooks/basic/mlflow-basic.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/mlflow-basic-self-logging.ipynb to notebook\n",
      "[NbConvertApp] Writing 13286 bytes to /mnt/code/notebooks/basic/mlflow-basic-self-logging.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/mlflow.ipynb to notebook\n",
      "[NbConvertApp] Writing 16957 bytes to /mnt/code/notebooks/basic/mlflow.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/mlflow-llm.ipynb to notebook\n",
      "[NbConvertApp] Writing 4439 bytes to /mnt/code/notebooks/basic/mlflow-llm.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/mlflow-schema-tracking.ipynb to notebook\n",
      "[NbConvertApp] Writing 12700 bytes to /mnt/code/notebooks/basic/mlflow-schema-tracking.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/pyspark_hyperparameter_search.ipynb to notebook\n",
      "[NbConvertApp] Writing 13643 bytes to /mnt/code/notebooks/basic/pyspark_hyperparameter_search.ipynb\n",
      "[NbConvertApp] Converting notebook /mnt/code/notebooks/basic/tensorboard_integration.ipynb to notebook\n",
      "[NbConvertApp] Writing 6348 bytes to /mnt/code/notebooks/basic/tensorboard_integration.ipynb\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --clear-output --inplace /mnt/code/notebooks/basic/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f1785-c463-43bc-9856-59b282486271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "tensorboard",
   "language": "python",
   "name": "tensorboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
