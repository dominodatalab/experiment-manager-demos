{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3483ed8c-cf80-4cd3-b949-f37af5b7074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import mlflow\n",
    "from mlflow.client import MlflowClient\n",
    "from mlflow.models import infer_signature, ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223b548-5473-4257-b163-37e89a19bd5c",
   "metadata": {},
   "source": [
    "### Model Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6648eb5-aff9-498a-b9bd-aa00d4c5351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "data = datasets.load_breast_cancer()\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, \n",
    "                                                    data.target,\n",
    "                                                    stratify=data.target)\n",
    "# Instantiating and fitting the model\n",
    "model = LogisticRegression(max_iter=1000)            \n",
    "model.fit(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25c049a3-93d2-40cc-b7d8-8edb0b7fa4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['mean radius': double (required), 'mean texture': double (required), 'mean perimeter': double (required), 'mean area': double (required), 'mean smoothness': double (required), 'mean compactness': double (required), 'mean concavity': double (required), 'mean concave points': double (required), 'mean symmetry': double (required), 'mean fractal dimension': double (required), 'radius error': double (required), 'texture error': double (required), 'perimeter error': double (required), 'area error': double (required), 'smoothness error': double (required), 'compactness error': double (required), 'concavity error': double (required), 'concave points error': double (required), 'symmetry error': double (required), 'fractal dimension error': double (required), 'worst radius': double (required), 'worst texture': double (required), 'worst perimeter': double (required), 'worst area': double (required), 'worst smoothness': double (required), 'worst compactness': double (required), 'worst concavity': double (required), 'worst concave points': double (required), 'worst symmetry': double (required), 'worst fractal dimension': double (required)]\n",
       "outputs: \n",
       "  [Tensor('int64', (-1,))]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting train features into a DataFrame\n",
    "X_train_df = pd.DataFrame(data=X_train, columns=data.feature_names)\n",
    "\n",
    "# Inferring the input signature\n",
    "signature = infer_signature(model_input=X_train_df, \n",
    "                           model_output=model.predict(X_test))\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "800392af-b7b6-46a0-8531-5046e5700870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  ['mean radius': double (required), 'mean texture': double (required), 'mean perimeter': double (required), 'mean area': double (required), 'mean smoothness': double (required), 'mean compactness': double (required), 'mean concavity': double (required), 'mean concave points': double (required), 'mean symmetry': double (required), 'mean fractal dimension': double (required), 'radius error': double (required), 'texture error': double (required), 'perimeter error': double (required), 'area error': double (required), 'smoothness error': double (required), 'compactness error': double (required), 'concavity error': double (required), 'concave points error': double (required), 'symmetry error': double (required), 'fractal dimension error': double (required), 'worst radius': double (required), 'worst texture': double (required), 'worst perimeter': double (required), 'worst area': double (required), 'worst smoothness': double (required), 'worst compactness': double (required), 'worst concavity': double (required), 'worst concave points': double (required), 'worst symmetry': double (required), 'worst fractal dimension': double (required)]\n",
       "outputs: \n",
       "  [double (required)]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an input schema for the breast cancer dataset\n",
    "input_schema = Schema(inputs=[ColSpec(type=\"double\", name=feature_name) \n",
    "                              for feature_name in data.feature_names])\n",
    "\n",
    "# Creating an output schema for the breast cancer dataset\n",
    "output_schema = Schema(inputs=[ColSpec(\"double\")])\n",
    "\n",
    "#Creating a signature from our schemas\n",
    "signature_manual = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "signature_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941984f4-9c43-44f2-90e6-077f7f38b4eb",
   "metadata": {},
   "source": [
    "### Save the model locally to /tmp/mymodel\n",
    "\n",
    "This is just to show how you can save and run the model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e92a355-dca9-4ac6-9539-fae173922966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['python_env.yaml',\n",
       " 'requirements.txt',\n",
       " 'model.pkl',\n",
       " 'MLmodel',\n",
       " 'conda.yaml',\n",
       " 'input_example.json']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "folder_path = \"/tmp/mymodel\"\n",
    "if os.path.exists(folder_path):\n",
    "        if os.path.isdir(folder_path):\n",
    "            shutil.rmtree(folder_path)\n",
    "            \n",
    "# Saving the model. Note the path. This will save the model under /mnt/model\n",
    "input_example = X_train_df.iloc[:1]\n",
    "mlflow.sklearn.save_model(sk_model=model, \n",
    "                          path=folder_path, \n",
    "                          signature=signature,\n",
    "                          input_example=input_example)\n",
    "##Verify that is looks good\n",
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879eef6-a744-4b09-b42e-c333a1a6a33f",
   "metadata": {},
   "source": [
    "### Review the output\n",
    "\n",
    "Especially take a look at the `requirements.txt` and the yaml files and the `requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b9dca-756c-4459-b58e-a45c3030944a",
   "metadata": {},
   "source": [
    "### Run the locally saved model\n",
    "\n",
    "This is a way all models should be run if you want them to be portable. This is the industry\n",
    "standard MLFLOW based mechanism to load and run models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ab9dc0a-afd3-44ea-a0bc-8e1b6ff3374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/code/notebooks/basic\n"
     ]
    }
   ],
   "source": [
    "#Run the locally saved model\n",
    "import os\n",
    "import pandas as pd\n",
    "def predict(model_uri,features):\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    return loaded_model.predict(features)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8778f713-1686-4b1d-9303-0c3be15d4032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_json(f'{cwd}/client/features.json', orient='records', lines=True)    \n",
    "predict(folder_path,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c323a-3d71-46c4-aa16-634c9b686783",
   "metadata": {},
   "source": [
    "### Now we register this model with Domino Experiment Manager\n",
    "\n",
    "1. Create an experiment with a meaningful name\n",
    "2. Create a registered model name\n",
    "3. Finally register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "529751e7-a72a-4f87-ba5f-5660333c49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists\n"
     ]
    }
   ],
   "source": [
    "prefix = 'TUTORIAL-COMPLEX-LOGGGING'\n",
    "starting_user_name = os.environ['DOMINO_STARTING_USERNAME']\n",
    "project_name = os.environ['DOMINO_PROJECT_NAME']\n",
    "\n",
    "experiment_name = f'{prefix}-{starting_user_name}-{project_name}'\n",
    "model_name = f'model-{prefix}-{starting_user_name}-{project_name}'\n",
    "\n",
    "\n",
    "client = MlflowClient()\n",
    "try:\n",
    "    client.create_registered_model(model_name)\n",
    "except:\n",
    "    print('Model already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f4ace-df69-4639-8cdf-b21a1a38de98",
   "metadata": {},
   "source": [
    "## The Most Important Part - Model Registration\n",
    "\n",
    "Pay close attention to not just the models that are being registered. But also the additional files we are choosing to add to the model registry. We can add anything our final image in our \n",
    "final execution environment will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45be92f5-fd89-44f1-8f6e-2e4000868e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2024/08/07 16:26:54 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos, version 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos\n",
      "Version: 4\n",
      "Description: \n",
      "Status: READY\n",
      "Stage: None\n"
     ]
    }
   ],
   "source": [
    "# Saving the model as an artifact in a run\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "run_id=''\n",
    "##Specify Dependencies implicitly\n",
    "with mlflow.start_run() as run:\n",
    "    # Obtaining the ID of this run\n",
    "    run_id = run.info.run_id\n",
    "    # Logging our model\n",
    "    #model_folder = 'mymodel'\n",
    "    model_folder = ''\n",
    "    model_client_folder = 'client'\n",
    "    model_templates_folder = 'templates'\n",
    "    model_entry_point = 'python'\n",
    "    model_command_line = 'client/execute_model.py'\n",
    "    model_info = mlflow.sklearn.log_model(sk_model=model, \n",
    "                             artifact_path=model_folder,  \n",
    "                             signature=signature,\n",
    "                             input_example=input_example)\n",
    "    ##Note these artifacts being logged.\n",
    "    mlflow.log_artifact(f'{cwd}/client/model.json',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/features.json',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/example_predict.py',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/execute_model.py',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/templates/Dockerfile.template',model_templates_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/templates/create_docker_image.sh.template',model_templates_folder)\n",
    "\n",
    "'''\n",
    "Tags are a way of passing metadata to the model version client. In our case it will be the \n",
    "external program that will download these model versions and publish images to foundry\n",
    "\n",
    "'''\n",
    "my_tags={}\n",
    "my_tags['MODEL_FOLDER']='mymodel'\n",
    "my_tags['MODEL_CLIENT_FOLDER']='client'\n",
    "my_tags['MODEL_ENTRY_POINT']='python'\n",
    "my_tags['MODEL_EXECUTE_PATH']='client/execute_model.py'\n",
    "\n",
    "model_src = RunsArtifactRepository.get_underlying_uri(f\"runs:/{run_id}/\")\n",
    "mv = client.create_model_version(model_name, model_src, run_id,tags=my_tags)\n",
    "print(\"Name: {}\".format(mv.name))\n",
    "print(\"Version: {}\".format(mv.version))\n",
    "print(\"Description: {}\".format(mv.description))\n",
    "print(\"Status: {}\".format(mv.status))\n",
    "print(\"Stage: {}\".format(mv.current_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9920bb-14c7-4a91-8241-5a568153fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now fetch the model from model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a8fe2d0-4d1c-4b10-b2b8-eaf7ead213f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Version\n",
      "<ModelVersion: aliases=[], creation_timestamp=1723048014481, current_stage='None', description='', last_updated_timestamp=1723048014481, name='model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos', run_id='22e7e16e367341faa5f373db89d8b1e7', run_link='', source='mlflow-artifacts:/mlflow/22e7e16e367341faa5f373db89d8b1e7/artifacts', status='READY', status_message='', tags={'MODEL_CLIENT_FOLDER': 'client',\n",
      " 'MODEL_ENTRY_POINT': 'python',\n",
      " 'MODEL_EXECUTE_PATH': 'client/execute_model.py',\n",
      " 'MODEL_FOLDER': 'mymodel',\n",
      " 'mlflow.domino.dataset_info': '66b3618dffe62d0ab852cd0b-66b3618dffe62d0ab852cd0a',\n",
      " 'mlflow.domino.environment_id': '66954257bbc5d36b228ddd74',\n",
      " 'mlflow.domino.environment_revision_id': '66954257bbc5d36b228ddd79',\n",
      " 'mlflow.domino.hardware_tier': 'small-k8s',\n",
      " 'mlflow.domino.project_id': '66b3618bffe62d0ab852cd05',\n",
      " 'mlflow.domino.project_name': 'Experiment-Manager-Demos',\n",
      " 'mlflow.domino.provenance_checkpoint_id': '66b361ceec337b3cd8fea647',\n",
      " 'mlflow.domino.run_id': '66b361a0ffe62d0ab852cd10',\n",
      " 'mlflow.domino.run_number': '1',\n",
      " 'mlflow.domino.user': 'integration-test',\n",
      " 'mlflow.domino.user_id': '669544681084e916359035ec',\n",
      " 'mlflow.source.git.branch': 'main',\n",
      " 'mlflow.source.git.commit': '27efc8cc2c8d302aac33feff59444a6564a6259d',\n",
      " 'mlflow.source.type': 'NOTEBOOK',\n",
      " 'mlflow.user': 'integration-test'}, user_id='', version='4'>\n",
      "Model Run Id\n",
      "22e7e16e367341faa5f373db89d8b1e7\n",
      "Model Download Path /tmp/models/model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos/v4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f119bc25d043f1a90445ed69a42b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 16:29:10 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/models/model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos/v4/'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version=4\n",
    "mv = client.get_model_version(model_name, model_version)\n",
    "print('Model Version')\n",
    "print(mv)\n",
    "\n",
    "run_id = mv.run_id\n",
    "print('Model Run Id')\n",
    "print(run_id)\n",
    "model_download_path = f'/tmp/models/{model_name}/v{model_version}'\n",
    "os.makedirs(model_download_path, exist_ok=True)\n",
    "print(f'Model Download Path {model_download_path}')\n",
    "client.download_artifacts(run_id, f\"\", model_download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577922d1-0bd7-4d9c-a5e6-79b1cb38d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /tmp/models/model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos/v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f0451bb-88d3-4ba8-acff-3bbd36386c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def create_file_from_template(template_string, context, output_file_path):\n",
    "    template = string.Template(template_string)\n",
    "    content = template.safe_substitute(context)\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0203d546-5faa-4062-98f4-c6a07babe63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_folder = 'templates'\n",
    "context = {\n",
    "        'model_name': model_name,\n",
    "        'model_version': model_version,\n",
    "        'model_download_folder': model_download_path,\n",
    "        'model_folder': mv.tags['MODEL_FOLDER'],\n",
    "        'model_client_folder': mv.tags['MODEL_CLIENT_FOLDER'],\n",
    "        'entry_point': mv.tags['MODEL_ENTRY_POINT'],\n",
    "        'command_line': mv.tags['MODEL_EXECUTE_PATH'],\n",
    "}\n",
    "\n",
    "if 'MODEL_TEMPLATES_FOLDER' in context:\n",
    "    templates_folder = context['MODEL_TEMPLATES_FOLDER']\n",
    "with open(f\"{model_download_path}/{templates_folder}/Dockerfile.template\", 'r') as file:\n",
    "    content = file.read()\n",
    "    output_file = f\"{model_download_path}/Dockerfile\"\n",
    "    create_file_from_template(content, context, output_file)\n",
    "with open(f\"{model_download_path}/{templates_folder}/create_docker_image.sh.template\", 'r') as file:\n",
    "    content = file.read()\n",
    "    output_file = f\"{model_download_path}/create_docker_image.sh\"    \n",
    "    create_file_from_template(content, context, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67fe5a43-95f8-4287-a55a-28ea1f456ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/models/model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos/v4\n"
     ]
    }
   ],
   "source": [
    "#Re Run the locally retrieved model\n",
    "print(model_download_path)\n",
    "cwd = os.getcwd()\n",
    "d = pd.read_json(f'{cwd}/client/features.json', orient='records', lines=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "723f754f-8982-4d33-aaf3-3be7a17eb6e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/tmp/models/model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos/v4/mymodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_download_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/mymodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m d \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_download_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/client/features.json\u001b[39m\u001b[38;5;124m'\u001b[39m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Result\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[65], line 5\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model_uri, features)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(model_uri,features):\n\u001b[0;32m----> 5\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loaded_model\u001b[38;5;241m.\u001b[39mpredict(features)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:900\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[1;32m    866\u001b[0m     model_uri: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    867\u001b[0m     suppress_warnings: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    868\u001b[0m     dst_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    869\u001b[0m     model_config: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    870\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyFuncModel:\n\u001b[1;32m    871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03m    Load a model stored in Python function format.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;124;03m                release without warning.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 900\u001b[0m     local_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[1;32m    903\u001b[0m         model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:106\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m        a local output path will be created.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_uri\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:85\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m     83\u001b[0m local_artifact_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(artifact_path))\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_artifact_path):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(local_artifact_path)\n",
      "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/tmp/models/model-TUTORIAL-COMPLEX-LOGGGING-integration-test-Experiment-Manager-Demos/v4/mymodel'"
     ]
    }
   ],
   "source": [
    "#Re Run the locally retrieved model\n",
    "import os\n",
    "import pandas as pd\n",
    "def predict(model_uri,features):\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    return loaded_model.predict(features)\n",
    "model_path = f\"{model_download_path}\"\n",
    "d = pd.read_json(f'{model_download_path}/client/features.json', orient='records', lines=True)\n",
    "result = predict(model_path,d)\n",
    "\n",
    "print(\"Model Result\")\n",
    "print(result)\n",
    "\n",
    "print(\"Input Dataset\")\n",
    "print(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ac6b8-6484-4d03-bd9b-70a8fa43e526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
